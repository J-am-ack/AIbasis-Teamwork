
# æ•°æ®è·å–
import requests
# from tenacity import retry, stop_after_attempt
# @retry(stop=stop_after_attempt(3))
# def safe_api_call():
# def get_weather(location: str, api_key: str) -> dict:
    

#     url = f"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=metric"
#     response = requests.get(url)
#     return {
#         "temp": response.json()["main"]["temp"],
#         "humidity": response.json()["main"]["humidity"],
#         "conditions": response.json()["weather"][0]["description"]
#     }


def get_weather(location: str, api_key: str) -> dict:
    url = f"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=metric"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        return {
            "temp": data["main"]["temp"],
            "humidity": data["main"]["humidity"],
            "conditions": data["weather"][0]["description"]
        }
    except (requests.exceptions.RequestException, KeyError) as e:
        print(f"Weather API error: {e}")
        return None  # æ·»åŠ é™çº§å¤„ç†é€»è¾‘


# å­˜å‚¨ç”¨æˆ·å†å²æ•°æ®
import sqlite3

conn = sqlite3.connect('users.db')
c = conn.cursor()
c.execute('''CREATE TABLE IF NOT EXISTS users
             (id TEXT PRIMARY KEY, age INT, gender TEXT, style_pref TEXT)''')


# c.execute('''CREATE TABLE IF NOT EXISTS history
#              (user_id TEXT, date TEXT, recommendation TEXToptions TEXT, 
#             selected_index INT)''')  # è®°å½•ç”¨æˆ·é€‰æ‹©çš„æ–¹æ¡ˆåºå·

# ä¿®æ­£å
c.execute('''CREATE TABLE IF NOT EXISTS history
             (user_id TEXT, date TEXT, 
             recommendation TEXT, 
             options TEXT,
             selected_index INT)''')



def build_features(user_id):
    # è·å–ç”¨æˆ·ç‰¹å¾
    user_data = c.execute("SELECT * FROM users WHERE id=?", (user_id,)).fetchone()
    
    # è·å–æœ€è¿‘3æ¬¡æ¨è
    history = c.execute("SELECT recommendation FROM history WHERE user_id=? ORDER BY date DESC LIMIT 3", (user_id,)).fetchall()
    
    return {
        "age": user_data[1],
        "gender": user_data[2],
        "preferred_styles": user_data[3].split(','),
        "recent_recommendations": [h[0] for h in history]
    }


# ä»promptçš„ä¿®æ”¹æ¥è®©å¤§æ¨¡å‹çš„è¾“å‡ºæœ‰è°ƒæ•´    
def construct_prompt(weather, features):
    prompt_template = f"""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç©¿è¡£é¡¾é—®ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯æä¾›å»ºè®®ï¼š
    - å½“å‰å¤©æ°”ï¼š{weather['temp']}â„ƒ, {weather['conditions']}, æ¹¿åº¦{weather['humidity']}%
    - ç”¨æˆ·ç‰¹å¾ï¼š{features['gender']}æ€§ï¼Œ{features['age']}å²
    - é£æ ¼åå¥½ï¼š{', '.join(features['preferred_styles'])}
    - è¿‘æœŸæ¨èè®°å½•ï¼š{features['recent_recommendations']}

    è¦æ±‚ï¼š
    1. é¿å…é‡å¤è¿‘1-2å¤©æ¨è
    2. è€ƒè™‘æ¸©åº¦å˜åŒ–å»ºè®®å¤–å¥—é€‰æ‹©
    3. ç»™å‡ºæ­é…ç†ç”±
    4. ä½¿ç”¨emojiå¢åŠ äº²å’ŒåŠ›
    5. æä¾›2-3å¥—æ–¹æ¡ˆä¾›ç”¨æˆ·é€‰æ‹©ï¼Œå¹¶è®°å½•ä»–ä»¬çš„é€‰æ‹©
    
    
    
    ä½œä¸ºä¸“ä¸šç©¿æ­åŠ©æ‰‹ï¼Œè¯·æä¾›3å¥—ä¸åŒçš„ç€è£…æ–¹æ¡ˆï¼š
    
    ã€ç¯å¢ƒä¿¡æ¯ã€‘
    - æ°”æ¸©ï¼š{weather['temp']}â„ƒ
    - å¤©æ°”çŠ¶å†µï¼š{weather['conditions']}
    - æ¹¿åº¦ï¼š{weather['humidity']}%
    - ç”¨æˆ·ç‰¹å¾ï¼š{features['gender']}æ€§ï¼Œ{features['age']}å²
    - é£æ ¼åå¥½ï¼š{', '.join(features['preferred_styles'])}
    
    ã€å†å²è®°å½•ã€‘ï¼ˆæœ€è¿‘3æ¬¡æ¨èï¼‰ï¼š
    {chr(10).join(features['recent_recommendations'])}
    
    ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
    1. ç”Ÿæˆ3å¥—å·®å¼‚æ˜æ˜¾çš„æ­é…æ–¹æ¡ˆ
    2. æ¯å¥—æ–¹æ¡ˆåŒ…å«ï¼šğŸ‘•ä¸Šè¡£ã€ğŸ‘–ä¸‹è£…ã€ğŸ§¥å¤–å¥—ã€ğŸ‘Ÿé‹å±¥ã€ğŸ’¡ç†ç”±
    3. ä½¿ç”¨emojiå¢åŠ äº²å’ŒåŠ›
    4. é¿å…ä¸å†å²æ¨èé‡å¤
    
    ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
    æ–¹æ¡ˆ1ï¼š
    ğŸ‘• ä¸Šè¡£ï¼š...
    ğŸ‘– ä¸‹è£…ï¼š...
    ğŸ§¥ å¤–å¥—ï¼š...
    ğŸ‘Ÿ é‹å±¥ï¼š...
    ğŸ’¡ ç†ç”±ï¼š...
    
    (å¯é€‰)
    æ–¹æ¡ˆ3ï¼š
    å»ºè®®æ ¼å¼ï¼š
    ğŸ‘• ä¸Šè¡£ï¼š...
    ğŸ‘– ä¸‹è£…ï¼š...
    ğŸ§¥ å¤–å¥—ï¼š...
    ğŸ‘Ÿ é‹å±¥ï¼š...
    ğŸ’¡ ç†ç”±ï¼š...
    
    ã€è¾“å‡ºç»“æŸè¯­ï¼š
    è¯·ä¸ºæˆ‘çš„å›ç­”æ‰“åˆ†ï¼1-5qwqï¼ˆå–œæ¬¢å°±5åˆ†å¥½è¯„çƒçƒqaq
    å¦‚æœéƒ½ä¸æ»¡æ„çš„è¯ï¼Œå¯ä»¥æä¾›æ›´å¤šä¿¡æ¯ï¼Œæˆ‘å°†ä¸ºä½ ç”Ÿæˆå…¶ä»–æ–¹æ¡ˆï¼
    

    """
    return prompt_template


from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
# åŠ è½½é‡åŒ–ç‰ˆæ¨¡å‹æå‡æ¨ç†é€Ÿåº¦
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen-1_8B-Chat-Int4", 
                                           device_map="auto", 
                                           trust_remote_code=True,
                                           torch_dtype=torch.float16,
                                        low_cpu_mem_usage=True)
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen-1_8B-Chat", 
                                        trust_remote_code=True)

def generate_recommendation(prompt):
    messages = [{"role": "user", "content": prompt}]
    response = model.chat(tokenizer, messages)
    return response


def diversified_generation(prompt):
    response = model.chat(
            tokenizer,
            messages=[{"role": "user", "content": prompt}],
            temperature=1.2,  # æé«˜éšæœºæ€§
            top_p=0.95,
            num_return_sequences=3
        )
    return response
def generate_alternative(user_id ,weather, features):
    """ç”Ÿæˆå·®å¼‚åŒ–å¤‡é€‰æ–¹æ¡ˆ"""
    # æ–¹æ³•1ï¼šè°ƒæ•´æ¨¡å‹å‚æ•°å¢åŠ å¤šæ ·æ€§
    
    # æ–¹æ³•2ï¼šä¿®æ”¹æç¤ºè¯è¦æ±‚ä¸åŒé£æ ¼
    alternative_prompt = f"""
    {construct_prompt(weather, features)}
    
    é™„åŠ è¦æ±‚ï¼š
    - è‡³å°‘åŒ…å«1å¥—ä¸ä¹‹å‰å®Œå…¨ä¸åŒçš„é£æ ¼
    - æ·»åŠ ä¸€ä¸ªã€Œç‰¹åˆ«æ¨èã€çš„åˆ›æ–°æ­é…
    """
    
    return diversified_generation(alternative_prompt)



def save_feedback(user_id, recommendation, rating):
    # å­˜å‚¨ç”¨æˆ·è¯„åˆ†ï¼ˆ1-5åˆ†ï¼‰
    c.execute("INSERT INTO feedback VALUES (?, ?, ?)", 
             (user_id, recommendation, rating))
    conn.commit()
    
    # # å½“å·®è¯„æ—¶è§¦å‘é‡æ–°ç”Ÿæˆ
    # if rating < 3:
    #     new_rec = generate_alternative(user_id,)
    #     # send_push_notification(user_id, new_rec)
    #     c.execute("INSERT INTO feedback VALUES (?, ?, ?)", 
    #          (user_id, new_rec, 4))  # è¿™é‡Œæˆ‘ä»¬äººä¸ºç»™å‡º
    #     conn.commit()



def full_workflow(user_id):
    # æ•°æ®è·å–
    # user_location = get_user_location(user_id)  # éœ€å®ç°ä½ç½®æŸ¥è¯¢
    
    
    weather  = get_weather("Beijing")
    #  weather = get_weather('Peking University')
    # é»˜è®¤ä½ç½®åœ¨ç™½é²¸å¤§å­¦
    features = build_features(user_id)
    
    # ç”Ÿæˆä¸»æ¨è
    main_prompt = construct_prompt(weather, features)
    recommendations = generate_recommendation(main_prompt)
    
    # è§£æå¤šæ–¹æ¡ˆè¾“å‡º
    parsed_options = parse_recommendations(recommendations)  # éœ€è¦å®ç°è§£æå™¨
    
    # å­˜å‚¨é€‰é¡¹
    save_feedback(user_id, recommendations, 3.5)
    # æ€ä¹ˆä¼ é€’ç”¨æˆ·æ‰“åˆ†
    
    # ç”¨æˆ·äº¤äº’ç•Œé¢
    # show_selection_interface(parsed_options)  # æ ¹æ®å®é™…å‰ç«¯å®ç°
    
    # ç­‰å¾…ç”¨æˆ·é€‰æ‹©å...
    # save_selection(user_id, selected_index)

def parse_recommendations(text):
    """è§£ææ¨¡å‹è¾“å‡ºçš„å¤šæ–¹æ¡ˆæ–‡æœ¬"""
    options = []
    current_option = {}
    
    for line in text.split('\n'):
        if 'æ–¹æ¡ˆ' in line and 'ï¼š' in line:
            if current_option:
                options.append(current_option)
                current_option = {}
        elif 'ğŸ‘•' in line:
            current_option['top'] = line.split('ï¼š')[-1].strip()
        elif 'ğŸ‘–' in line:
            current_option['bottom'] = line.split('ï¼š')[-1].strip()
        elif 'ğŸ§¥' in line:
            current_option['coat'] = line.split('ï¼š')[-1].strip()
        elif 'ğŸ‘Ÿ' in line:
            current_option['shoes'] = line.split('ï¼š')[-1].strip()
        elif 'ğŸ’¡' in line:
            current_option['reason'] = line.split('ï¼š')[-1].strip()
    
    return options[:3]  # æœ€å¤šè¿”å›3ä¸ªæ–¹æ¡ˆ



if __name__ == "__main__":
    # åˆå§‹åŒ–æµ‹è¯•ç”¨æˆ·
    c.execute("INSERT OR IGNORE INTO users VALUES (?, ?, ?, ?)", 
             ("test_user", 18, "ç”·", "ä¼‘é—²,è¿åŠ¨"))
    conn.commit()
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    full_workflow("test_user")
    
    # æ‰“å°ç»“æœ
    print(c.execute("SELECT * FROM history").fetchall())